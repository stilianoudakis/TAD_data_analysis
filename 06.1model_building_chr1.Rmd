---
title: "Modelling Chromosome 1"
author: "Spiro Stilianoudakis"
date: "May 16, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading Libraries

```{r }
#library(MultiAssayExperiment)
library(GenomicRanges)
#library(IRanges)
library(caret)
library(data.table)
library(gbm)
library(pROC)
library(plyr)
library(dplyr)
library(DMwR)
library(gridExtra)
library(nortest)

packages = c("MultiAssayExperiment", "GenomicRanges", "IRanges", "RaggedExperiment", "SummarizedExperiment", "caret", "data.table", "survival", "gbm", "pROC", "dplyr", "ggplot2", "e1071", "DMwR", "gridExtra", "randomForest", "rpart", "rpart.plot", "glmnet", "gridExtra", "qqman", "rms", "igraph", "ggraph", "RColorBrewer",
"nortest")


package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})
```

# Reading in data

```{r}
setwd("C:/Users/Spiro Stilianoudakis/Documents/TAD_data/Rdata")

logitdata <- readRDS("logitdata2.rds")

```

# Removing specific variables prior to analysis

```{r}

logitdata <- logitdata[,-which(colnames(logitdata)=="A" 
                             | colnames(logitdata)=="B"
                             | colnames(logitdata)=="UCNE"
                             | colnames(logitdata)=="UCNE_score" 
                             | colnames(logitdata)=="UCNE_dist"
                             | colnames(logitdata)=="gerp_score")]

dim(logitdata)
#2766314     101

```


# Isolating Chromosome 1

```{r}

chr1data <- logitdata[which(logitdata$CHR=="chr1"),]
dim(chr1data)
#247632    101


```

# Transforming the distance variables and gerp/ucne score variables
```{r}
cont_vars <- chr1data[,grep("dist", colnames(chr1data))]
dim(cont_vars)
#247632     48

#performing anderson-darling test for normality on all continuous variables
adtests <- apply(cont_vars, 2, FUN = function(x){ad.test(x)$p.value})
which(adtests>.05)
#all variables have distributions significantly different from normality

#perform a log transformation with base 2
cols <- c(grep("dist",colnames(chr1data)))
chr1data[,cols] <- apply(chr1data[,cols], 2, function(x){log(x + 1, base=2)})


prop.table(table(chr1data$y))   #0.99342169 0.00657831 
```


# Filtering data

```{r include=FALSE}
#Identify near-zero variance predictors
nzv <- nearZeroVar(chr1data[,-1], saveMetrics= TRUE)
nzv[nzv$nzv,]
nzvar <- rownames(nzv[nzv$nzv,])

#Removing zero variance predictors
chr1data_f <- chr1data[, -which(colnames(chr1data) %in% nzvar)]
dim(chr1data_f)
#247632   63

#Identifying Correlated Predictors
#descrCor <-  cor(chr1data_rf[,grep("dist",colnames(chr1data_rf))])
#summary(descrCor[upper.tri(descrCor)])
#highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .99)
#highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
#corvars <- colnames(chr1data_rf)[highlyCorDescr]
#chr1data_rf2 <- chr1data_rf[,-which(colnames(chr1data_rf) %in% corvars)]
#descrCor2 <- cor(chr1data_rf2[,grep("dist",colnames(chr1data_rf2))])
#summary(descrCor2[upper.tri(descrCor2)])

#check for linear dependencies
comboinfo <- findLinearCombos(chr1data_f)
comboinfo
chr1data_f <- chr1data_f[,-comboinfo$remove]
dim(chr1data_f)
#247632     62

```


# Randomly sampling to create balanced dataset

```{r}

chr1data_rf <- rbind.data.frame(chr1data_f[which(chr1data_f$y==1),],
                           chr1data_f[sample(which(chr1data_f$y==0),
                                              length(which(chr1data_f$y==1))),])

dim(chr1data_rf)
table(chr1data_rf$y)
  

```

# shuffle data first since significance variable is not randomized

```{r}
set.seed(123)
g <- runif(nrow(chr1data_rf))
chr1data_rf <- chr1data_rf[order(g),]

```


# Splitting the data

```{r}


#inTrainingSet <- sample(length(chr1data_rf$y),length(chr1data_rf$y)*.7)
#train <- chr1data_rf[inTrainingSet,]
#test <- chr1data_rf[-inTrainingSet,]

#prop.table(table(train$y))   #0.5109649 0.4890351  
#dim(train)  #2280   71


set.seed(3432)
inTrainingSet <- createDataPartition(chr1data_rf$y,p=.7,list=FALSE)
train <- chr1data_rf[inTrainingSet,]
test <- chr1data_rf[-inTrainingSet,]

prop.table(table(train$y))   #0.5 0.5 
dim(train)  #2282   62

train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
levels(train$y) <- c("No", "Yes")


```

# Classic GLM method

```{r}
#glm treats second factor level as event of interest
glmModel <- glm(y ~ ., 
                data = train, 
                family = binomial)

pred.glmModel <- predict(glmModel, newdata=test, type="response")

roc.glmModel <- roc(test$y, pred.glmModel)

auc.glmModel <- pROC::auc(roc.glmModel)
#0.8116

```

# Establishing tuning/training parameters

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary)

#train$y <- factor(train$y)
#test$y <- factor(test$y)
#levels(train$y) <- c("No", "Yes")

```


# Decision Tree

```{r include=FALSE}
#form <- as.formula(y ~ .)
#tree.1 <- rpart(form,
#                data=train) #, control=rpart.control(minsplit=20,cp=0))

#prp(tree.1)					# Will plot the tree
#prp(tree.1,varlen=3)

#new.tree.1 <- prp(tree.1,snip=TRUE)$obj # interactively trim the tree
#prp(new.tree.1) # display the new tree
#fancyRpartPlot(new.tree.1)

#tree.2 <- rpart(form,data=train,control=rpart.control(minsplit=20,cp=0.007))			# A more reasonable tree
#prp(tree.2)                                     # A fast plot													
#fancyRpartPlot(tree.2)

```

# CART model

```{r}

set.seed(2014)

#train_smote$y <- as.numeric(as.character(train_smote$y))
#train_smote$y <- factor(train_smote$y)
#levels(train$y) <- c("No", "Yes")

cartModel <- train(y ~ ., data=train, method = "rpart", metric="ROC", trControl = fitControl, tuneLength=5)

pred.cartModel <- as.vector(predict(cartModel, newdata=test, type="prob")[,"Yes"])


roc.cartModel <- pROC::roc(test$y, pred.cartModel)

auc.cartModel <- pROC::auc(roc.cartModel)
#0.7476

```


# Random Forest

```{r include=FALSE}
#We begin by creating a baseline model using the recommended tuning parameters

control <- trainControl(method="cv", number=5)
mtry <- floor(sqrt(ncol(train)-1))
tunegrid <- expand.grid(.mtry=mtry)
set.seed(2014)
rfdefault <- train(y ~ ., data=train, method = "rf", metric="ROC", trControl = fitControl, verbose=FALSE,tuneGrid=tunegrid, tuneLength=5)
predictions<-as.vector(predict(rfdefault, newdata=test, type="prob")[,"Yes"])
confusionMatrix(predictions,test$y)
roc.rfdefault <- pROC::roc(test$y, predictions)
auc.rfdefault <- pROC::auc(roc.rfdefault)
#0.7898

#determining the best number of variables randomly sampled as candidates at each split
set.seed(5430)
bestmtry <- tuneRF(train[,-1],train$y,
                   improve=.01,trace=T,plot=T) #suggests mtry=4

#determining best number of trees
tunegrid <- expand.grid(.mtry=4)
modellist <- list()
for (ntree in c(50,200,500,1000)) {
  set.seed(333)
  fit <- train(y~., data=train, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
  key <- toString(ntree)
  modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)

set.seed(1006)
rfModel <- train(y~., data=train, 
                    method="rf", 
                    metric="ROC", 
                    tuneGrid=tunegrid, 
                    trControl=fitControl, 
                    ntree=200)


pred.rfModel <- as.vector(predict(rfModel, newdata=test, type="prob")[,"Yes"])

roc.rfModel <- pROC::roc(test$y, pred.rfModel)

auc.rfModel <- pROC::auc(roc.rfModel)
#0.7868


varImp(rfModel$finalModel)
plot(varImp(rfModel,scale=TRUE))
rf.varplot <- cbind.data.frame(Predictors=rownames(data.frame(varImp(rfModel,scale=TRUE)[1])),
                                   Importance=data.frame(varImp(rfModel,scale=TRUE)[1])$Overall)
rf.varplot <- rf.varplot[order(rf.varplot$Importance),]
dim(rf.varplot)
rf.varplot2 <- rf.varplot[42:61,]
rf.varplot2$Predictors <- factor(rf.varplot2$Predictors,levels=rf.varplot2$Predictors)
(p <- ggplot(rf.varplot2) + geom_point(aes(Importance,Predictors)) +ggtitle("Variable Importance Plot for Random Forest")) 

ggplot(rf.varplot2, aes(x=Predictors, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Random Forest") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="blue") +
  coord_flip()
  #theme(axis.text.x = element_text(angle = 90, hjust = 1))


```

# GBM

```{r}
set.seed(2014)

grid <- expand.grid(n.trees=c(50,200,500,1000),shrinkage=c(0.01,0.05,0.1,0.5),n.minobsinnode = c(3,5,10),interaction.depth=c(1,5,10))

#grid <- expand.grid(interaction.depth = seq(6,16, by = 2),
#                    n.trees = seq(500,1500,by=200),
#                    shrinkage = .01, #c(0.01,0.1),
#                    n.minobsinnode = c(10))


gbmModel <- train(y ~ ., data=train, method = "gbm", metric="ROC", trControl = fitControl, verbose=FALSE, tuneGrid=grid)

gbmModel
ggplot(gbmModel) + theme(legend.position = "top")

pred.gbmModel <- as.vector(predict(gbmModel, newdata=test, type="prob")[,"Yes"])

roc.gbmModel <- pROC::roc(test$y, pred.gbmModel)

auc.gbmModel <- pROC::auc(roc.gbmModel)
#0.7925



varImp(gbmModel)
gbm.data <- data.frame(varImp(gbmModel)[1])
gbm.data2 <- cbind.data.frame(Predictors=rownames(gbm.data),Importance=gbm.data$Overall)
gbm.data2 <- gbm.data2[order(gbm.data2$Importance),]
gbm.data2 <- gbm.data2[42:61,]
gbm.data2 <- gbm.data2[order(gbm.data2$Importance),]
gbm.data2$Predictors <- factor(gbm.data2$Predictors,levels=gbm.data2$Predictors)
(p <- ggplot(gbm.data2) + geom_point(aes(Importance,Predictors)) + ggtitle("Variable Importance Plot for GBM Model"))

ggplot(gbm.data2, aes(x=Predictors, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Gradient Boosting Machine") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="red") +
  coord_flip()
  #theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

# Elastic Net

```{r}

#creating a grid of values for alpha and lambda that minimizes cross validation error
lambda.grid <- 10^seq(2,-2,length=100)
alpha.grid <- seq(0,1,length=10)

searchgrid <- expand.grid(alpha=alpha.grid, lambda=lambda.grid)

set.seed(2014)

eNetModel <- train(y ~ ., data=train, 
                   method = "glmnet",
                   tuneGrid=searchgrid,
                   metric="ROC", 
                   trControl = fitControl, 
                   family="binomial", 
                   standardize=FALSE)
eNetModel$bestTune

#eNetModel <- eNetModel$finalModel

pred.eNetModel <- as.vector(predict(eNetModel, newdata=test, type="prob")[,"Yes"])

roc.eNetModel <- pROC::roc(test$y, pred.eNetModel)

auc.eNetModel <- pROC::auc(roc.eNetModel)
#0.7876



enetdata <- varImp(eNetModel)$importance
enetdata2 <- data.frame(Feature=rownames(enetdata), Importance=enetdata$Overall)
enetdata2$Feature <- as.character(enetdata2$Feature)
enetdata2 <- enetdata2[order(enetdata2$Importance),]
enetdata2 <- enetdata2[42:61,]
enetdata2$Feature <- factor(enetdata2$Feature, levels=enetdata2$Feature[order(enetdata2$Importance)])

enetp <- ggplot(enetdata2, aes(x=Feature, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Gradient Boosting Machine") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="green") +
  coord_flip()
enetp
  #theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# SVM

```{r}

set.seed(5354)

svmModel <- train(y ~., data = train, method = "svmRadial",
  trControl=fitControl,
  metric="ROC",
  tuneLength = 10)

grid_radial <- expand.grid(sigma = c(0,0.01, 0.02, 0.025, 0.03, 0.04,
 0.05, 0.06, 0.07,0.08, 0.09, 0.1, 0.25, 0.5, 0.75,0.9),
 C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75,
 1, 1.5, 2,5))
svmModel <- train(y ~., data = train, method = "svmRadial",
                    trControl=fitControl,
                    metric="ROC",
                    tuneGrid = grid_radial,
                    tuneLength = 10)
 

svm.c <- train(y ~., data = train,
               method='svmRadial',
               trControl=fitControl,
               metric="ROC",tuneLength = 10)

plot(svm.c)

pred.svmModel <- as.vector(predict(svm.c, newdata=test, type="prob")[,"Yes"])

roc.svmModel <- pROC::roc(test$y, pred.svmModel)

auc.svmModel <- pROC::auc(roc.svmModel)
#0.7659

```


# Neural Network

```{r}

nnetGrid <- expand.grid(.size=1:10,
                        .decay=c(0,.1,1,2))
maxSize <- max(nnetGrid$.size)
numWts <- 1*(maxSize*(length(dim(train)[2])) + maxSize + 1)

set.seed(5346)
nnetModel <- train(y ~ ., data=train,
                   method="nnet",
                   metric="ROC",
                   trControl=fitControl,
                   tuneLength=5,
                   trace=FALSE,
                   maxit=2000)

plot(nnetModel)

pred.nnetModel <- as.vector(predict(nnetModel, newdata=test, type="prob")[,"Yes"])

roc.nnetModel <- pROC::roc(test$y, pred.nnetModel)

auc.nnetModel <- pROC::auc(roc.nnetModel)

```


# Plotting model performance

```{r}
test.auc <- data.frame(model=c("glm","gbm","glmnet","cart","rForest"),auc=c(auc.glmModel, auc.gbmModel, auc.eNetModel, auc.cartModel, auc.rfModel))

test.auc <- test.auc[order(test.auc$auc, decreasing=TRUE),]

test.auc$model <- factor(test.auc$model, levels=test.auc$model)

test.auc

p<-ggplot(data=test.auc, aes(x=model, y=auc)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme_minimal()
p

plot(roc.rfModel, legacy.axes=TRUE, col="red")
lines(roc.gbmModel, col="blue")
lines(roc.eNetModel, col="green")



```

# Comparing results when using smote

```{r}
# Using SMOTE


# Splitting the data
set.seed(5228)
inTrainingSet <- createDataPartition(chr1data_f$y,p=.7,list=FALSE)
train <- chr1data_f[inTrainingSet,]
test <- chr1data_f[-inTrainingSet,]

prop.table(table(train$y))   # 0.993434982 0.006565018 
dim(train)  #173343     64

train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
levels(train$y) <- c("No", "Yes")
levels(test$y) <- c("No", "Yes")
#all categorical variables must be factors
str(train)
set.seed(111)
train_smote <- SMOTE(y ~ ., data=train, perc.over = 100, perc.under = 200)
table(train_smote$y)
#  No  Yes 
#2224 2224 
prop.table(table(train_smote$y))   #0.5 0.5 
dim(train_smote)
#4448   62

# Classic GLM method
glmModel_sm <- glm(y ~ ., 
                data = train_smote, 
                family = binomial)
pred.glmModel_sm <- predict(glmModel_sm, newdata=test, type="response")
roc.glmModel_sm <- roc(test$y, pred.glmModel_sm)
auc.glmModel_sm <- pROC::auc(roc.glmModel_sm)
#0.7884

# Establishing tuning/training parameters
fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 10,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary)

# CART model
#set.seed(2014)
#cartModel_sm <- train(y ~ ., data=train_smote, method = "rpart", metric="ROC", trControl = fitControl, tuneLength=5)
#pred.cartModel_sm <- as.vector(predict(cartModel_sm, newdata=test, type="prob")[,"Yes"])
#roc.cartModel_sm <- pROC::roc(test$y, pred.cartModel_sm)
#auc.cartModel_sm <- pROC::auc(roc.cartModel_sm)
#0.771

# Elastic Net
set.seed(2014)
eNetModel_sm <- train(y ~ ., data=train_smote, method = "glmnet", metric="ROC", trControl = fitControl, family="binomial", tuneLength=5)
pred.eNetModel_sm <- as.vector(predict(eNetModel_sm, newdata=test, type="prob")[,"Yes"])
roc.eNetModel_sm <- pROC::roc(test$y, pred.eNetModel_sm)
auc.eNetModel_sm <- pROC::auc(roc.eNetModel_sm)
#0.7916

# GBM
set.seed(2014)
gbmModel_sm <- train(y ~ ., data=train_smote, method = "gbm", metric="ROC", trControl = fitControl, verbose=FALSE, tuneLength=5)
pred.gbmModel_sm <- as.vector(predict(gbmModel_sm, newdata=test, type="prob")[,"Yes"])
roc.gbmModel_sm <- pROC::roc(test$y, pred.gbmModel_sm)
auc.gbmModel_sm <- pROC::auc(roc.gbmModel_sm)
#0.7815

# Random Forest
set.seed(2014)
rfModel_sm <- train(y ~ ., data=train_smote, method = "rf", metric="ROC", trControl = fitControl, verbose=FALSE, tuneLength=5)
pred.rfModel_sm <- as.vector(predict(rfModel_sm, newdata=test, type="prob")[,"Yes"])
roc.rfModel_sm <- pROC::roc(test$y, pred.rfModel_sm)
auc.rfModel_sm <- pROC::auc(roc.rfModel_sm)
#0.784

#SVM
set.seed(5354)
#svmModel <- train(y ~., data = train_smote, method = "svmRadial",
#  trControl=fitControl,
#  metric="ROC",
#  tuneLength = 10)
#grid_radial <- expand.grid(sigma = c(0,0.01, 0.02, 0.025, 0.03, 0.04,
# 0.05, 0.06, 0.07,0.08, 0.09, 0.1, 0.25, 0.5, 0.75,0.9),
# C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75,
# 1, 1.5, 2,5))
svm.c <- train(y ~., data = train_smote,
               method='svmRadial',
               trControl=fitControl,
               metric="ROC",tuneLength = 5)

#plot(svmModel)
pred.svmModel <- as.vector(predict(svm.c, newdata=test, type="prob")[,"Yes"])
roc.svmModel <- pROC::roc(test$y, pred.svmModel)
auc.svmModel <- pROC::auc(roc.svmModel)

#Neural Network
#nnetGrid <- expand.grid(.size=1:10,
#                        .decay=c(0,.1,1,2))
#maxSize <- max(nnetGrid$.size)
#numWts <- 1*(maxSize*(length(dim(train)[2])) + maxSize + 1)
set.seed(5346)
nnetModel <- train(y ~ ., data=train_smote,
                   method="nnet",
                   metric="ROC",
                   trControl=fitControl,
                   tuneLength=5,
                   trace=FALSE,
                   maxit=2000)
pred.nnetModel <- as.vector(predict(nnetModel, newdata=test, type="prob")[,"Yes"])
roc.nnetModel <- pROC::roc(test$y, pred.nnetModel)
auc.nnetModel <- pROC::auc(roc.nnetModel)

# Plotting model performance
test.auc_sm <- data.frame(model=c("glm","gbm","glmnet","cart","rForest"),auc=c(auc.glmModel_sm, auc.gbmModel_sm, auc.eNetModel_sm, auc.cartModel_sm, auc.rfModel_sm))
test.auc_sm <- test.auc_sm[order(test.auc_sm$auc, decreasing=TRUE),]
test.auc_sm$model <- factor(test.auc_sm$model, levels=test.auc_sm$model)
test.auc_sm
p_sm<-ggplot(data=test.auc_sm, aes(x=model, y=auc)) +
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal()
p_sm

grid.arrange(p, p_sm, ncol=2)

plot(roc.rfModel_sm, legacy.axes=TRUE, col="red")
lines(roc.gbmModel_sm, col="blue")
lines(roc.eNetModel_sm, col="green")

#feature importance plots
#RF
rf.varplot_sm <- cbind.data.frame(Predictors=rownames(data.frame(varImp(rfModel_sm,scale=TRUE)[1])),
                                   Importance=data.frame(varImp(rfModel_sm,scale=TRUE)[1])$Overall)
rf.varplot_sm <- rf.varplot_sm[order(rf.varplot_sm$Importance),]
dim(rf.varplot_sm)
rf.varplot2_sm <- rf.varplot_sm[51:70,]
rf.varplot2_sm$Predictors <- factor(rf.varplot2_sm$Predictors,levels=rf.varplot2_sm$Predictors)
(p <- ggplot(rf.varplot2_sm) + geom_point(aes(Importance,Predictors)) +ggtitle("Variable Importance Plot for Random Forest")) 

ggplot(rf.varplot2_sm, aes(x=Predictors, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Random Forest") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="blue") +
  coord_flip()

#GBM
varImp(gbmModel_sm)
gbm.data_sm <- data.frame(varImp(gbmModel_sm)[1])
gbm.data2_sm <- cbind.data.frame(Predictors=rownames(gbm.data_sm),Importance=gbm.data_sm$Overall)
gbm.data2_sm <- gbm.data2_sm[order(gbm.data2_sm$Importance),]
gbm.data2_sm <- gbm.data2_sm[51:70,]
gbm.data2_sm <- gbm.data2_sm[order(gbm.data2_sm$Importance),]
gbm.data2_sm$Predictors <- factor(gbm.data2_sm$Predictors,levels=gbm.data2_sm$Predictors)
(p <- ggplot(gbm.data2_sm) + geom_point(aes(Importance,Predictors)) + ggtitle("Variable Importance Plot for GBM Model"))

ggplot(gbm.data2_sm, aes(x=Predictors, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Gradient Boosting Machine") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="red") +
  coord_flip()

#ElasticNet
enetdata_sm <- varImp(eNetModel_sm)$importance
enetdata2_sm <- data.frame(Feature=rownames(enetdata_sm), Importance=enetdata_sm$Overall)
enetdata2_sm$Feature <- as.character(enetdata2_sm$Feature)
enetdata2_sm <- enetdata2_sm[order(enetdata2_sm$Importance),]
enetdata2_sm <- enetdata2_sm[51:70,]
enetdata2_sm$Feature <- factor(enetdata2_sm$Feature, levels=enetdata2_sm$Feature[order(enetdata2_sm$Importance)])

ggplot(enetdata2_sm, aes(x=Feature, 
                        y=Importance)) +
  xlab("Predictors") +
  ylab("Importance") +
  #ggtitle("Importance Plot for Gradient Boosting Machine") +
  geom_bar(stat="identity", 
           width=.5, 
           position="dodge",
           fill="green") +
  coord_flip()

```


# Comparing Models

```{r include=FALSE}
#Without SMOTE

#finding common features between the models
intersect(rf.varplot2$Predictors,gbm.data2$Predictors)
commonfeats <- intersect(intersect(rf.varplot2$Predictors,gbm.data2$Predictors),enetdata2$Feature)

rf.varplot2$ranking <- rank(-rf.varplot2$Importance)
gbm.data2$ranking <- rank(-gbm.data2$Importance)
enetdata2$ranking <- rank(-enetdata2$Importance)

#rankings between rf, gbm, and elastic net
commonfeatsdf <- data.frame(Features = commonfeats,
                          RandomForest = rf.varplot2$ranking[rf.varplot2$Predictors %in% commonfeats],
                          RFImp = rf.varplot2$Importance[rf.varplot2$Predictors %in% commonfeats],
                          GBM = gbm.data2[order(match(gbm.data2$Predictors, commonfeats)),]$ranking[gbm.data2[order(match(gbm.data2$Predictors, commonfeats)),]$Predictors %in% commonfeats],
                          GBMImp = gbm.data2[order(match(gbm.data2$Predictors, commonfeats)),]$Importance[gbm.data2[order(match(gbm.data2$Predictors, commonfeats)),]$Predictors %in% commonfeats],
                          ElasticNet = enetdata2[order(match(enetdata2$Feature, commonfeats)),]$ranking[enetdata2[order(match(enetdata2$Feature, commonfeats)),]$Feature %in% commonfeats],
                          ENetImp = enetdata2[order(match(enetdata2$Feature, commonfeats)),]$Importance[enetdata2[order(match(enetdata2$Feature, commonfeats)),]$Feature %in% commonfeats]
                          )



#With SMOTE

#finding common features between the models
intersect(rf.varplot2_sm$Predictors,gbm.data2_sm$Predictors)
commonfeats_sm <- intersect(intersect(rf.varplot2_sm$Predictors,gbm.data2_sm$Predictors),enetdata2_sm$Feature)

rf.varplot2_sm$ranking <- rank(-rf.varplot2_sm$Importance)
gbm.data2_sm$ranking <- rank(-gbm.data2_sm$Importance)
enetdata2_sm$ranking <- rank(-enetdata2_sm$Importance)

#rankings between rf, gbm, and elastic net
commonfeatsdf_sm <- data.frame(Features = commonfeats_sm,
                          RandomForest = rf.varplot2_sm$ranking[rf.varplot2_sm$Predictors %in% commonfeats_sm],
                          RFImp = rf.varplot2_sm$Importance[rf.varplot2_sm$Predictors %in% commonfeats_sm],
                          GBM = gbm.data2_sm[order(match(gbm.data2_sm$Predictors, commonfeats_sm)),]$ranking[gbm.data2_sm[order(match(gbm.data2_sm$Predictors, commonfeats_sm)),]$Predictors %in% commonfeats_sm],
                          GBMImp = gbm.data2_sm[order(match(gbm.data2_sm$Predictors, commonfeats_sm)),]$Importance[gbm.data2_sm[order(match(gbm.data2_sm$Predictors, commonfeats_sm)),]$Predictors %in% commonfeats_sm],
                          ElasticNet = enetdata2_sm[order(match(enetdata2_sm$Feature, commonfeats_sm)),]$ranking[enetdata2_sm[order(match(enetdata2_sm$Feature, commonfeats_sm)),]$Feature %in% commonfeats_sm],
                          ENetImp = enetdata2_sm[order(match(enetdata2_sm$Feature, commonfeats_sm)),]$Importance[enetdata2_sm[order(match(enetdata2_sm$Feature, commonfeats_sm)),]$Feature %in% commonfeats_sm]
                          )


```
